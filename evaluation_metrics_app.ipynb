{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed63ade-2e0f-4b0e-86e7-10eb6a2ca316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from numpy import sqrt, argmax\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "from plotnine import *\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import FloatSlider, IntSlider, HBox, VBox, interactive_output, Layout, AppLayout\n",
    "\n",
    "from functools import lru_cache\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module = \"plotnine\\..*\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2342d2-4854-4e6c-9fb5-292b43c40cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERATE DATA ###\n",
    "# temporarily calling data generation function for each plot due to subplotting/refresh issue\n",
    "\n",
    "common_params = {\n",
    "    \"n_samples\": 400,\n",
    "    \"n_features\": 2,\n",
    "    \"n_informative\": 2,\n",
    "    \"n_redundant\": 0,\n",
    "    \"n_clusters_per_class\": 1,\n",
    "    \"flip_y\": 0,\n",
    "    \"random_state\": 11,\n",
    "    \"shuffle\": False\n",
    "}\n",
    "    \n",
    "@lru_cache(32)\n",
    "def generate_data_for_plotting(class_imbalance, separation, cutoff):\n",
    "    \n",
    "    X, y = make_classification(**common_params, weights=[class_imbalance], class_sep = separation)\n",
    "    \n",
    "    # fit the data to a logistic regression model (no train/test split for demo purposes)\n",
    "    logreg = sklearn.linear_model.LogisticRegression()\n",
    "    logreg.fit(X, y)\n",
    "    \n",
    "    probs = logreg.predict_proba(X)[:,1]\n",
    "    y_pred = [1 if i > cutoff else 0 for i in probs]\n",
    "    \n",
    "    # create dataframe for plotting\n",
    "    df = pd.DataFrame({\n",
    "        \"x1\": X[:,0],\n",
    "        \"x2\": X[:,1],\n",
    "        \"y\": y,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"pr\": probs\n",
    "        }).astype({'y': 'category'})\n",
    "    \n",
    "    df['color'] = np.select([(df['y'] == df['y_pred']), (df['y'] != df['y_pred'])],\n",
    "                            ['true','false']\n",
    "    )\n",
    "\n",
    "    return logreg, df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f8b43e5-557f-42a1-87bd-59ae0ed24d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE PLOTS ###\n",
    "\n",
    "colors = [\"#34585F\", \"#A4B89E\", \"#C6CDA7\", \"#EFE0B7\", \"#BEAC7C\"]\n",
    "    \n",
    "def plot_decision_boundary(class_imbalance, separation, cutoff):\n",
    "\n",
    "    # prep data\n",
    "    logreg, df = generate_data_for_plotting(class_imbalance, separation, cutoff)\n",
    "    \n",
    "    b = logreg.intercept_[0]\n",
    "    w1, w2 = logreg.coef_.T\n",
    "    c = -b/w2\n",
    "    m = -w1/w2\n",
    "    xmin, xmax = -2.5, 4.25\n",
    "    ymin, ymax = -3, 3\n",
    "    \n",
    "    # xmin, xmax = df['x1'].min()-1.25, df['x1'].max()+1 \n",
    "    # ymin, ymax = df['x2'].min()-0.5, df['x2'].max()+0.5 \n",
    "    \n",
    "    xd = np.linspace(start=xmin, stop=xmax, num=len(df.index))\n",
    "    yd = m*xd + c\n",
    "    \n",
    "    # plot data\n",
    "    p1 = (ggplot(df, aes(x = 'x1', y = 'x2', fill = 'y')) +\n",
    "            geom_point(aes(color = 'color'), size = 3.5, alpha = .85) +\n",
    "            geom_abline(intercept = c,\n",
    "                slope = m,\n",
    "                linetype='dotted') +\n",
    "            geom_ribbon(mapping = aes(x = xd, ymin = yd, ymax = float('inf')), \n",
    "                fill = '#83ad76', alpha = .15) +\n",
    "            geom_ribbon(mapping = aes(x = xd, ymin = yd, ymax = float('-inf')), \n",
    "                fill = '#196675', alpha = .1) +\n",
    "            scale_fill_manual(labels = ['True 0', 'True 1'], values = ['#196675', '#83ad76']) +\n",
    "            scale_color_manual(labels = ['Incorrect pred'], limits = ['false'], values = ['#e03a2f', 'grey']) +\n",
    "            scale_x_continuous(limits=(xmin,xmax), expand = (0,0)) +\n",
    "            scale_y_continuous(limits=(ymin,ymax), expand = (0,0)) +\n",
    "            labs(x = None,\n",
    "                 y = None,\n",
    "                 fill = \"\",\n",
    "                 color = \"\") +\n",
    "                 labs(title = \"Classifier decision boundary\",\n",
    "                      x = r'$x_1$',\n",
    "                      y = r'$x_2$') +\n",
    "            coord_flip() +\n",
    "            theme_minimal() +\n",
    "            theme(legend_position=(.68, .15), \n",
    "                  legend_direction='horizontal') +\n",
    "            guides(color = guide_legend(override_aes = {'fill': \"white\"}))\n",
    "    ).draw()\n",
    "\n",
    "def plot_metrics_bar_chart(class_imbalance, separation, cutoff):\n",
    "    \n",
    "    # prep data\n",
    "    logreg, df = generate_data_for_plotting(class_imbalance, separation, cutoff)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(df['y'], df['y_pred'])\n",
    "    recall = metrics.recall_score(df['y'], df['y_pred'])\n",
    "    precision = metrics.precision_score(df['y'], df['y_pred'])\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict({\n",
    "        'Accuracy': [accuracy],\n",
    "        'Recall': [recall],\n",
    "        'Precision': [precision]\n",
    "    }).melt(var_name='cols', value_name='vals')\n",
    "    \n",
    "    metrics_df['vals'] = metrics_df['vals'].round(2)\n",
    "    \n",
    "    # plot data\n",
    "    (ggplot(metrics_df, aes(x='cols', y='vals', fill='cols')) + \n",
    "              geom_col() +\n",
    "              geom_text(aes(label = 'vals'), nudge_y=-.1, color = \"white\") +\n",
    "              scale_fill_manual(values = colors, \n",
    "                                guide = False) +\n",
    "              ylim(0,1) +\n",
    "              labs(title = \"Accuracy, precision, and recall\",\n",
    "                   x = None,\n",
    "                   y = None) +\n",
    "              theme_minimal() \n",
    "    ).draw()\n",
    "\n",
    "\n",
    "def plot_roc_curve(class_imbalance, separation, cutoff):\n",
    "    \n",
    "    # prep data\n",
    "    logreg, df = generate_data_for_plotting(class_imbalance, separation, cutoff)\n",
    "\n",
    "    fpr, tpr, threshold = metrics.roc_curve(df['y'], df['pr'])\n",
    "    roc_auc = metrics.auc(fpr, tpr).round(3)\n",
    "\n",
    "    gmeans = sqrt(tpr * (1-fpr))\n",
    "    ix = argmax(gmeans)\n",
    "    \n",
    "    df = pd.DataFrame(dict(fpr = fpr, \n",
    "                           tpr = tpr, \n",
    "                           roc_auc = roc_auc))\n",
    "    \n",
    "    # plot data\n",
    "    (ggplot(df, aes(x = 'fpr', y = 'tpr')) + \n",
    "        geom_line(color = \"#34585F\", size = 1.5) + \n",
    "        geom_abline(linetype = 'dashed') +\n",
    "        geom_point(aes(x = fpr[ix], y = tpr[ix]), size = 7, color = \"#A4B89E\", alpha = .2) +\n",
    "        geom_text(aes(x = 0.85, y = 0, label = ['AUC: ' + str(roc_auc)])) +\n",
    "        labs(title = \"ROC AUC\",\n",
    "             x = \"False positive rate\",\n",
    "             y = \"True positive rate\") +\n",
    "        theme_minimal()).draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d46e3bf-c1ae-446b-86dd-637c370c5d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CREATE WIDGETS ###\n",
    "\n",
    "# define widgets\n",
    "cb_widget = FloatSlider(description = \"Imbalance\",\n",
    "                        continuous_update = False,\n",
    "                        min=0.1, max=0.9, step=0.1, value=0.5)\n",
    "sep_widget = FloatSlider(description = \"Separation\",\n",
    "                        continuous_update = False,\n",
    "                         min=.1, max=1.1, step=0.1, value=0.6)\n",
    "cutoff_widget = FloatSlider(description = \"Cutoff\",\n",
    "                        continuous_update = False,\n",
    "                         min=.1, max=.9, step=0.1, value=0.5)\n",
    "\n",
    "\n",
    "# interact plots with widgets\n",
    "scatter_plot = interactive_output(plot_decision_boundary, {'class_imbalance': cb_widget, \n",
    "                                                   'separation': sep_widget,\n",
    "                                                   'cutoff': cutoff_widget})\n",
    "metrics_plot = interactive_output(plot_metrics_bar_chart, {'class_imbalance': cb_widget, \n",
    "                                                   'separation': sep_widget,\n",
    "                                                   'cutoff': cutoff_widget})\n",
    "roc_plot = interactive_output(plot_roc_curve, {'class_imbalance': cb_widget, \n",
    "                                                   'separation': sep_widget,\n",
    "                                                   'cutoff': cutoff_widget})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6161b570-3484-47a1-b0bb-a8702e46c229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".box_style{\n",
       "    background-color: #fff;\n",
       "}\n",
       "p{\n",
       "    font-style: italic;\n",
       "    font-size: .75rem;\n",
       "    line-height: .85rem;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".box_style{\n",
    "    background-color: #fff;\n",
    "}\n",
    "p{\n",
    "    font-style: italic;\n",
    "    font-size: .75rem;\n",
    "    line-height: .85rem;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0a6b63cb-7453-48af-b9ad-835d2e9d7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET UP APP ###\n",
    "\n",
    "# header = widgets.HTML(\"<h1>Visualizing class imbalance and model evaluation metrics</h1>\")\n",
    "# footer = widgets.HTML(\"\"\"<p>Note: Results should be taken with a grain of salt, as this visualization is only meant to convey the intuition behind the \n",
    "#                       effects of imbalanced data and other parameters on model evaluation metrics.</p>\"\"\",\n",
    "#                       layout=widgets.Layout(margin='30px 0 0 0'))\n",
    "\n",
    "# widget_box = VBox([cb_widget, sep_widget, cutoff_widget], layout=widgets.Layout(margin='3px', \n",
    "#                                                                                 border='solid 1px #fff', \n",
    "#                                                                                 flex_flow='row wrap', \n",
    "#                                                                                 align_content='flex-start', \n",
    "#                                                                                 justify_content='flex-start'))\n",
    "# widget_box.add_class(\"box_style\")\n",
    "\n",
    "# plots_box = HBox([scatter_plot, metrics_plot, roc_plot], layout=widgets.Layout(width='100%', \n",
    "#                                                                                display = 'flex',\n",
    "#                                                                                flex_flow = 'row',\n",
    "#                                                                                justify_content = 'space-between',\n",
    "#                                                                                align_items = 'center'))\n",
    "\n",
    "# app = AppLayout(header=header,\n",
    "#           left_sidebar=widget_box,\n",
    "#           center=plots_box,\n",
    "#           right_sidebar=None,\n",
    "#           footer=footer,\n",
    "#           pane_widths=['250px', 1, 1],\n",
    "#           pane_heights=['140px', 1, '140px'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d13ff-08a5-4a3d-9193-48210cb69bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DISPLAY APP ###\n",
    "\n",
    "#display(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0f26fb8b-ea6d-4549-a497-8500b5f91d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET UP APP\n",
    "\n",
    "header = widgets.HTML(\"<h1>Visualizing class imbalance and model evaluation metrics</h1>\")\n",
    "footer = widgets.HTML(\"\"\"<p>Note: Results should be taken with a grain of salt, as this visualization is only meant to convey the intuition behind the \n",
    "                      effects of imbalanced data and other parameters on model evaluation metrics.</p>\"\"\",\n",
    "                      layout=widgets.Layout(margin='40px 0 0 0'))\n",
    "\n",
    "widget_box = VBox([cb_widget, sep_widget, cutoff_widget], layout=widgets.Layout(margin='10px 0 15px 0', \n",
    "                                                                                border='solid 1px #cecece', \n",
    "                                                                                flex_flow='row wrap', \n",
    "                                                                                align_content='center', \n",
    "                                                                                justify_content='center'))\n",
    "widget_box.add_class(\"box_style\")\n",
    "\n",
    "plot_box = HBox([scatter_plot, metrics_plot, roc_plot], layout=widgets.Layout(margin='15px 0 15px 0', \n",
    "                                                                              width='100%', \n",
    "                                                                              display = 'flex', \n",
    "                                                                              flex_flow = 'row',\n",
    "                                                                              justify_content = 'space-between',\n",
    "                                                                              align_items = 'center'))\n",
    "app = AppLayout(header=header,\n",
    "          left_sidebar=None,\n",
    "          center=VBox([widget_box, plot_box]),\n",
    "          right_sidebar=None,\n",
    "          footer=footer,          \n",
    "          #pane_widths=['250px', 1, 1],\n",
    "          pane_heights=['80px', 1, '100px'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e020b28d-c68f-4b21-aad4-f0c5c6318dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b21fc255f3a44c1b2f8098f6eb8bf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AppLayout(children=(HTML(value='<h1>Visualizing class imbalance and model evaluation metrics</h1>', layout=Lay…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DISPLAY APP\n",
    "\n",
    "display(app)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
